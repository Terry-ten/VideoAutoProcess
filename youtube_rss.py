#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
YouTube RSSç›‘æ§ç³»ç»Ÿ - æ— éœ€APIå¯†é’¥
ä½¿ç”¨YouTubeçš„RSS feedè·å–é¢‘é“è§†é¢‘ä¿¡æ¯
"""

import re
import requests
import xml.etree.ElementTree as ET
from datetime import datetime
from typing import List, Dict, Optional
from urllib.parse import urlparse, parse_qs
import logging

class YouTubeRSSMonitor:
    def __init__(self):
        self.logger = logging.getLogger(__name__)
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36'
        })
    
    def extract_channel_id(self, url: str) -> Optional[str]:
        """ä»å„ç§YouTube URLæ ¼å¼æå–é¢‘é“ID"""
        try:
            # ç›´æ¥çš„é¢‘é“ID URL
            if '/channel/' in url:
                return url.split('/channel/')[-1].split('/')[0].split('?')[0]
            
            # @username æ ¼å¼
            if '/@' in url:
                username = url.split('/@')[-1].split('/')[0].split('?')[0]
                return self._get_channel_id_from_username(username)
            
            # /c/channelname æ ¼å¼  
            if '/c/' in url:
                channel_name = url.split('/c/')[-1].split('/')[0].split('?')[0]
                return self._get_channel_id_from_custom_name(channel_name)
            
            # /user/ æ ¼å¼
            if '/user/' in url:
                username = url.split('/user/')[-1].split('/')[0].split('?')[0]
                return self._get_channel_id_from_username(username)
            
            return None
            
        except Exception as e:
            self.logger.error(f"æå–é¢‘é“IDå¤±è´¥: {e}")
            return None
    
    def _get_channel_id_from_username(self, username: str) -> Optional[str]:
        """é€šè¿‡ç”¨æˆ·åè·å–é¢‘é“ID"""
        try:
            # å°è¯•è®¿é—®é¢‘é“ä¸»é¡µè·å–çœŸå®çš„é¢‘é“ID
            url = f"https://www.youtube.com/@{username}"
            response = self.session.get(url, timeout=10)
            
            if response.status_code == 200:
                # ä»é¡µé¢HTMLä¸­æå–é¢‘é“ID
                pattern = r'"channelId":"([^"]+)"'
                match = re.search(pattern, response.text)
                if match:
                    return match.group(1)
                
                # å¤‡ç”¨æ–¹æ¡ˆï¼šæŸ¥æ‰¾å…¶ä»–æ¨¡å¼
                pattern = r'externalId":"([^"]+)"'
                match = re.search(pattern, response.text)
                if match:
                    return match.group(1)
            
            return None
            
        except Exception as e:
            self.logger.error(f"é€šè¿‡ç”¨æˆ·åè·å–é¢‘é“IDå¤±è´¥: {e}")
            return None
    
    def _get_channel_id_from_custom_name(self, custom_name: str) -> Optional[str]:
        """é€šè¿‡è‡ªå®šä¹‰åç§°è·å–é¢‘é“ID"""
        try:
            url = f"https://www.youtube.com/c/{custom_name}"
            response = self.session.get(url, timeout=10)
            
            if response.status_code == 200:
                pattern = r'"channelId":"([^"]+)"'
                match = re.search(pattern, response.text)
                if match:
                    return match.group(1)
            
            return None
            
        except Exception as e:
            self.logger.error(f"é€šè¿‡è‡ªå®šä¹‰åç§°è·å–é¢‘é“IDå¤±è´¥: {e}")
            return None
    
    def get_channel_info(self, channel_url: str) -> Optional[Dict]:
        """è·å–é¢‘é“ä¿¡æ¯"""
        try:
            channel_id = self.extract_channel_id(channel_url)
            if not channel_id:
                self.logger.error("æ— æ³•æå–é¢‘é“ID")
                return None
            
            # è·å–é¢‘é“RSSä¿¡æ¯
            rss_url = f"https://www.youtube.com/feeds/videos.xml?channel_id={channel_id}"
            response = self.session.get(rss_url, timeout=10)
            
            if response.status_code != 200:
                self.logger.error(f"è·å–RSSå¤±è´¥: {response.status_code}")
                return None
            
            # è§£æRSS XML
            root = ET.fromstring(response.content)
            
            # æå–é¢‘é“ä¿¡æ¯
            ns = {
                'atom': 'http://www.w3.org/2005/Atom',
                'yt': 'http://www.youtube.com/xml/schemas/2015',
                'media': 'http://search.yahoo.com/mrss/'
            }
            
            title = root.find('.//atom:title', ns)
            author = root.find('.//atom:author/atom:name', ns)
            
            channel_info = {
                'channel_id': channel_id,
                'channel_name': title.text if title is not None else 'Unknown',
                'channel_url': channel_url,
                'rss_url': rss_url,
                'description': f"é€šè¿‡RSSç›‘æ§çš„é¢‘é“",
                'subscriber_count': None  # RSSä¸­æ²¡æœ‰è®¢é˜…è€…æ•°é‡
            }
            
            return channel_info
            
        except Exception as e:
            self.logger.error(f"è·å–é¢‘é“ä¿¡æ¯å¤±è´¥: {e}")
            return None
    
    def get_latest_videos(self, channel_id: str, max_results: int = 50) -> List[Dict]:
        """è·å–é¢‘é“æœ€æ–°è§†é¢‘"""
        try:
            rss_url = f"https://www.youtube.com/feeds/videos.xml?channel_id={channel_id}"
            response = self.session.get(rss_url, timeout=10)
            
            if response.status_code != 200:
                self.logger.error(f"è·å–RSSå¤±è´¥: {response.status_code}")
                return []
            
            # è§£æRSS XML
            root = ET.fromstring(response.content)
            
            ns = {
                'atom': 'http://www.w3.org/2005/Atom',
                'yt': 'http://www.youtube.com/xml/schemas/2015',
                'media': 'http://search.yahoo.com/mrss/'
            }
            
            videos = []
            entries = root.findall('.//atom:entry', ns)
            
            for entry in entries[:max_results]:
                try:
                    # æå–è§†é¢‘ä¿¡æ¯
                    video_id = entry.find('.//yt:videoId', ns)
                    title = entry.find('.//atom:title', ns)
                    published = entry.find('.//atom:published', ns)
                    updated = entry.find('.//atom:updated', ns)
                    link = entry.find('.//atom:link[@rel="alternate"]', ns)
                    
                    # åª’ä½“ä¿¡æ¯
                    media_group = entry.find('.//media:group', ns)
                    description = None
                    thumbnail_url = None
                    
                    if media_group is not None:
                        desc_elem = media_group.find('.//media:description', ns)
                        if desc_elem is not None:
                            description = desc_elem.text
                        
                        thumb_elem = media_group.find('.//media:thumbnail', ns)
                        if thumb_elem is not None:
                            thumbnail_url = thumb_elem.get('url')
                    
                    video_data = {
                        'video_id': video_id.text if video_id is not None else '',
                        'channel_id': channel_id,
                        'title': title.text if title is not None else 'Unknown',
                        'description': description or '',
                        'video_url': link.get('href') if link is not None else '',
                        'published_at': self._parse_datetime(published.text) if published is not None else datetime.now(),
                        'updated_at': self._parse_datetime(updated.text) if updated is not None else datetime.now(),
                        'thumbnail_url': thumbnail_url,
                        'duration': None,  # RSSä¸­æ²¡æœ‰æ—¶é•¿ä¿¡æ¯
                        'view_count': None,  # RSSä¸­æ²¡æœ‰è§‚çœ‹æ¬¡æ•°
                        'like_count': None,  # RSSä¸­æ²¡æœ‰ç‚¹èµæ•°
                        'comment_count': None  # RSSä¸­æ²¡æœ‰è¯„è®ºæ•°
                    }
                    
                    videos.append(video_data)
                    
                except Exception as e:
                    self.logger.error(f"è§£æè§†é¢‘æ¡ç›®å¤±è´¥: {e}")
                    continue
            
            return videos
            
        except Exception as e:
            self.logger.error(f"è·å–æœ€æ–°è§†é¢‘å¤±è´¥: {e}")
            return []
    
    def _parse_datetime(self, datetime_str: str) -> datetime:
        """è§£æRSSä¸­çš„æ—¶é—´æ ¼å¼"""
        try:
            # RSSæ—¶é—´æ ¼å¼: 2024-01-15T10:00:00+00:00
            if 'T' in datetime_str:
                datetime_str = datetime_str.split('+')[0].split('Z')[0]
                return datetime.fromisoformat(datetime_str)
            else:
                return datetime.now()
        except:
            return datetime.now()

def test_rss_monitor():
    """æµ‹è¯•RSSç›‘æ§åŠŸèƒ½"""
    print("ğŸ”§ æµ‹è¯•YouTube RSSç›‘æ§ç³»ç»Ÿ")
    print("=" * 50)
    
    monitor = YouTubeRSSMonitor()
    
    # æµ‹è¯•é¢‘é“
    test_urls = [
        "https://www.youtube.com/@mkbhd",
        "https://www.youtube.com/@veritasium",
    ]
    
    for url in test_urls:
        print(f"\næµ‹è¯•é¢‘é“: {url}")
        print("-" * 30)
        
        # è·å–é¢‘é“ä¿¡æ¯
        channel_info = monitor.get_channel_info(url)
        if channel_info:
            print(f"âœ“ é¢‘é“åç§°: {channel_info['channel_name']}")
            print(f"âœ“ é¢‘é“ID: {channel_info['channel_id']}")
            
            # è·å–æœ€æ–°è§†é¢‘
            videos = monitor.get_latest_videos(channel_info['channel_id'], max_results=3)
            print(f"âœ“ æ‰¾åˆ° {len(videos)} ä¸ªè§†é¢‘")
            
            for i, video in enumerate(videos, 1):
                print(f"  {i}. {video['title']}")
                print(f"     å‘å¸ƒ: {video['published_at'].strftime('%Y-%m-%d %H:%M')}")
                print(f"     URL: {video['url']}")
                
        else:
            print("âŒ è·å–é¢‘é“ä¿¡æ¯å¤±è´¥")

if __name__ == '__main__':
    test_rss_monitor() 