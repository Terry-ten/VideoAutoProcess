#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
YouTube RSSç›‘æ§ç³»ç»Ÿ - æ— éœ€APIå¯†é’¥
ä½¿ç”¨YouTubeçš„RSS feedè·å–é¢‘é“è§†é¢‘ä¿¡æ¯
"""

import re
import ssl
import requests
import xml.etree.ElementTree as ET
from datetime import datetime
from typing import List, Dict, Optional
from urllib.parse import urlparse, parse_qs
import logging
from urllib3.util.retry import Retry
from requests.adapters import HTTPAdapter
import urllib3
import subprocess

# ç¦ç”¨SSLè­¦å‘Š
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

class YouTubeRSSMonitor:
    def __init__(self):
        self.logger = logging.getLogger(__name__)
        self.session = self._create_session()
    
    def _create_session(self):
        """åˆ›å»ºä¼˜åŒ–çš„requests session"""
        session = requests.Session()
        
        # é…ç½®é‡è¯•ç­–ç•¥
        retry_strategy = Retry(
            total=3,
            backoff_factor=1,
            status_forcelist=[429, 500, 502, 503, 504],
        )
        
        adapter = HTTPAdapter(max_retries=retry_strategy)
        session.mount('http://', adapter)
        session.mount('https://', adapter)
        
        # è®¾ç½®ç”¨æˆ·ä»£ç†å’Œå…¶ä»–headers
        session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
            'Accept-Language': 'en-US,en;q=0.5',
            'Accept-Encoding': 'gzip, deflate',
            'Connection': 'keep-alive',
        })
        
        return session
    
    def _safe_request(self, url: str, timeout: int = 10) -> Optional[requests.Response]:
        """å®‰å…¨çš„HTTPè¯·æ±‚ï¼Œå¤„ç†SSLé—®é¢˜"""
        try:
            # é¦–å…ˆå°è¯•æ­£å¸¸è¯·æ±‚
            response = self.session.get(url, timeout=timeout)
            return response
        except (ssl.SSLError, requests.exceptions.SSLError) as e:
            self.logger.warning(f"SSLé”™è¯¯ï¼Œå°è¯•ä¸éªŒè¯SSLè¯ä¹¦: {e}")
            try:
                # å¦‚æœSSLå¤±è´¥ï¼Œå°è¯•ä¸éªŒè¯è¯ä¹¦
                response = self.session.get(url, timeout=timeout, verify=False)
                return response
            except Exception as e2:
                self.logger.error(f"è¯·æ±‚å®Œå…¨å¤±è´¥: {e2}")
                return None
        except Exception as e:
            self.logger.error(f"è¯·æ±‚å¤±è´¥: {e}")
            return None
    
    def _curl_request(self, url: str) -> Optional[str]:
        """ä½¿ç”¨ç³»ç»Ÿcurlå‘½ä»¤è·å–æ•°æ®ï¼ˆå¤‡ç”¨æ–¹æ¡ˆï¼‰"""
        try:
            # ä½¿ç”¨curlå‘½ä»¤ï¼Œå¿½ç•¥SSLè¯ä¹¦éªŒè¯
            cmd = ['curl', '-k', '-s', '--max-time', '10', url]
            result = subprocess.run(cmd, capture_output=True, text=True, timeout=15)
            
            if result.returncode == 0 and result.stdout:
                return result.stdout
            else:
                self.logger.error(f"curlè¯·æ±‚å¤±è´¥: {result.stderr}")
                return None
                
        except subprocess.TimeoutExpired:
            self.logger.error("curlè¯·æ±‚è¶…æ—¶")
            return None
        except Exception as e:
            self.logger.error(f"curlè¯·æ±‚å¼‚å¸¸: {e}")
            return None
    
    def extract_channel_id(self, url: str) -> Optional[str]:
        """ä»å„ç§YouTube URLæ ¼å¼æå–é¢‘é“ID"""
        try:
            # ç›´æ¥çš„é¢‘é“ID URL
            if '/channel/' in url:
                return url.split('/channel/')[-1].split('/')[0].split('?')[0]
            
            # @username æ ¼å¼
            if '/@' in url:
                username = url.split('/@')[-1].split('/')[0].split('?')[0]
                return self._get_channel_id_from_username(username)
            
            # /c/channelname æ ¼å¼  
            if '/c/' in url:
                channel_name = url.split('/c/')[-1].split('/')[0].split('?')[0]
                return self._get_channel_id_from_custom_name(channel_name)
            
            # /user/ æ ¼å¼
            if '/user/' in url:
                username = url.split('/user/')[-1].split('/')[0].split('?')[0]
                return self._get_channel_id_from_username(username)
            
            return None
            
        except Exception as e:
            self.logger.error(f"æå–é¢‘é“IDå¤±è´¥: {e}")
            return None
    
    def _get_channel_id_from_username(self, username: str) -> Optional[str]:
        """é€šè¿‡ç”¨æˆ·åè·å–é¢‘é“ID"""
        try:
            # å°è¯•è®¿é—®é¢‘é“ä¸»é¡µè·å–çœŸå®çš„é¢‘é“ID
            url = f"https://www.youtube.com/@{username}"
            response = self._safe_request(url)
            
            if response and response.status_code == 200:
                # ä»é¡µé¢HTMLä¸­æå–é¢‘é“ID
                pattern = r'"channelId":"([^"]+)"'
                match = re.search(pattern, response.text)
                if match:
                    return match.group(1)
                
                # å¤‡ç”¨æ–¹æ¡ˆï¼šæŸ¥æ‰¾å…¶ä»–æ¨¡å¼
                pattern = r'externalId":"([^"]+)"'
                match = re.search(pattern, response.text)
                if match:
                    return match.group(1)
            
            return None
            
        except Exception as e:
            self.logger.error(f"é€šè¿‡ç”¨æˆ·åè·å–é¢‘é“IDå¤±è´¥: {e}")
            return None
    
    def _get_channel_id_from_custom_name(self, custom_name: str) -> Optional[str]:
        """é€šè¿‡è‡ªå®šä¹‰åç§°è·å–é¢‘é“ID"""
        try:
            url = f"https://www.youtube.com/c/{custom_name}"
            response = self._safe_request(url)
            
            if response and response.status_code == 200:
                pattern = r'"channelId":"([^"]+)"'
                match = re.search(pattern, response.text)
                if match:
                    return match.group(1)
            
            return None
            
        except Exception as e:
            self.logger.error(f"é€šè¿‡è‡ªå®šä¹‰åç§°è·å–é¢‘é“IDå¤±è´¥: {e}")
            return None
    
    def get_channel_info(self, channel_url: str) -> Optional[Dict]:
        """è·å–é¢‘é“ä¿¡æ¯"""
        try:
            channel_id = self.extract_channel_id(channel_url)
            if not channel_id:
                self.logger.error("æ— æ³•æå–é¢‘é“ID")
                return None
            
            # è·å–é¢‘é“RSSä¿¡æ¯
            rss_url = f"https://www.youtube.com/feeds/videos.xml?channel_id={channel_id}"
            response = self._safe_request(rss_url)
            
            if not response or response.status_code != 200:
                self.logger.error(f"è·å–RSSå¤±è´¥: {response.status_code if response else 'No response'}")
                return None
            
            # è§£æRSS XML
            root = ET.fromstring(response.content)
            
            # æå–é¢‘é“ä¿¡æ¯
            ns = {
                'atom': 'http://www.w3.org/2005/Atom',
                'yt': 'http://www.youtube.com/xml/schemas/2015',
                'media': 'http://search.yahoo.com/mrss/'
            }
            
            title = root.find('.//atom:title', ns)
            author = root.find('.//atom:author/atom:name', ns)
            
            channel_info = {
                'channel_id': channel_id,
                'channel_name': title.text if title is not None else 'Unknown',
                'channel_url': channel_url,
                'rss_url': rss_url,
                'description': f"é€šè¿‡RSSç›‘æ§çš„é¢‘é“",
                'subscriber_count': None  # RSSä¸­æ²¡æœ‰è®¢é˜…è€…æ•°é‡
            }
            
            return channel_info
            
        except Exception as e:
            self.logger.error(f"è·å–é¢‘é“ä¿¡æ¯å¤±è´¥: {e}")
            return None
    
    def get_latest_videos(self, channel_id: str, max_results: int = 50) -> List[Dict]:
        """è·å–é¢‘é“æœ€æ–°è§†é¢‘"""
        try:
            rss_url = f"https://www.youtube.com/feeds/videos.xml?channel_id={channel_id}"
            
            # é¦–å…ˆå°è¯•requests
            response = self._safe_request(rss_url)
            xml_content = None
            
            if response and response.status_code == 200:
                xml_content = response.content
            else:
                # å¦‚æœrequestså¤±è´¥ï¼Œå°è¯•curl
                self.logger.info("requestså¤±è´¥ï¼Œå°è¯•ä½¿ç”¨curl")
                curl_result = self._curl_request(rss_url)
                if curl_result:
                    xml_content = curl_result.encode('utf-8')
                else:
                    self.logger.error(f"è·å–RSSå¤±è´¥: æ‰€æœ‰æ–¹æ³•éƒ½å¤±è´¥")
                    return []
            
            # è§£æRSS XML
            root = ET.fromstring(xml_content)
            
            ns = {
                'atom': 'http://www.w3.org/2005/Atom',
                'yt': 'http://www.youtube.com/xml/schemas/2015',
                'media': 'http://search.yahoo.com/mrss/'
            }
            
            videos = []
            entries = root.findall('.//atom:entry', ns)
            
            for entry in entries[:max_results]:
                try:
                    # æå–è§†é¢‘ä¿¡æ¯
                    video_id = entry.find('.//yt:videoId', ns)
                    title = entry.find('.//atom:title', ns)
                    published = entry.find('.//atom:published', ns)
                    updated = entry.find('.//atom:updated', ns)
                    link = entry.find('.//atom:link[@rel="alternate"]', ns)
                    
                    # åª’ä½“ä¿¡æ¯
                    media_group = entry.find('.//media:group', ns)
                    description = None
                    thumbnail_url = None
                    
                    if media_group is not None:
                        desc_elem = media_group.find('.//media:description', ns)
                        if desc_elem is not None:
                            description = desc_elem.text
                        
                        thumb_elem = media_group.find('.//media:thumbnail', ns)
                        if thumb_elem is not None:
                            thumbnail_url = thumb_elem.get('url')
                    
                    video_data = {
                        'video_id': video_id.text if video_id is not None else '',
                        'channel_id': channel_id,
                        'title': title.text if title is not None else 'Unknown',
                        'description': description or '',
                        'video_url': link.get('href') if link is not None else '',
                        'published_at': self._parse_datetime(published.text) if published is not None else datetime.now(),
                        'updated_at': self._parse_datetime(updated.text) if updated is not None else datetime.now(),
                        'thumbnail_url': thumbnail_url,
                        'duration': None,  # RSSä¸­æ²¡æœ‰æ—¶é•¿ä¿¡æ¯
                        'view_count': None,  # RSSä¸­æ²¡æœ‰è§‚çœ‹æ¬¡æ•°
                        'like_count': None,  # RSSä¸­æ²¡æœ‰ç‚¹èµæ•°
                        'comment_count': None  # RSSä¸­æ²¡æœ‰è¯„è®ºæ•°
                    }
                    
                    videos.append(video_data)
                    
                except Exception as e:
                    self.logger.error(f"è§£æè§†é¢‘æ¡ç›®å¤±è´¥: {e}")
                    continue
            
            return videos
            
        except Exception as e:
            self.logger.error(f"è·å–æœ€æ–°è§†é¢‘å¤±è´¥: {e}")
            return []
    
    def _parse_datetime(self, datetime_str: str) -> datetime:
        """è§£æRSSä¸­çš„æ—¶é—´æ ¼å¼"""
        try:
            # RSSæ—¶é—´æ ¼å¼: 2024-01-15T10:00:00+00:00
            if 'T' in datetime_str:
                datetime_str = datetime_str.split('+')[0].split('Z')[0]
                return datetime.fromisoformat(datetime_str)
            else:
                return datetime.now()
        except:
            return datetime.now()

def test_rss_monitor():
    """æµ‹è¯•RSSç›‘æ§åŠŸèƒ½"""
    print("ğŸ”§ æµ‹è¯•YouTube RSSç›‘æ§ç³»ç»Ÿ")
    print("=" * 50)
    
    monitor = YouTubeRSSMonitor()
    
    # æµ‹è¯•é¢‘é“
    test_urls = [
        "https://www.youtube.com/@mkbhd",
        "https://www.youtube.com/@veritasium",
    ]
    
    for url in test_urls:
        print(f"\næµ‹è¯•é¢‘é“: {url}")
        print("-" * 30)
        
        # è·å–é¢‘é“ä¿¡æ¯
        channel_info = monitor.get_channel_info(url)
        if channel_info:
            print(f"âœ“ é¢‘é“åç§°: {channel_info['channel_name']}")
            print(f"âœ“ é¢‘é“ID: {channel_info['channel_id']}")
            
            # è·å–æœ€æ–°è§†é¢‘
            videos = monitor.get_latest_videos(channel_info['channel_id'], max_results=3)
            print(f"âœ“ æ‰¾åˆ° {len(videos)} ä¸ªè§†é¢‘")
            
            for i, video in enumerate(videos, 1):
                print(f"  {i}. {video['title']}")
                print(f"     å‘å¸ƒ: {video['published_at'].strftime('%Y-%m-%d %H:%M')}")
                print(f"     URL: {video['video_url']}")
                
        else:
            print("âŒ è·å–é¢‘é“ä¿¡æ¯å¤±è´¥")

if __name__ == '__main__':
    test_rss_monitor() 